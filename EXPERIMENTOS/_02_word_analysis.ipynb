{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INPUTS**:\n",
    "* *data/01_CIE_emedicine_info.xlsx*\n",
    "* *data/risk_texts.xlsx*\n",
    "* *data/112/EM_112_ICD_selected.csv*\n",
    "* **STOPWORDS**\n",
    "\n",
    "**OUTPUTS**:\n",
    "* *data/02_CIE_tokenized_info.xlsx*\n",
    "* *data/02_112_patients_db.xlsx*\n",
    "\n",
    "**NOTAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/nacho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re #regex\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "#from googletrans import Translator\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data - Virtual Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webs = pd.read_excel(\"data/01_CIE_emedicine_info.xlsx\")\n",
    "webs.fillna('')\n",
    "\n",
    "risk_words = pd.read_excel(\"data/risk_texts.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data - 112 Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_112 = pd.read_csv(\"data/112/EM_112_ICD_selected.csv\")[['DIA_CODIGO','PAC_SEXO','LAB_RIESGO_VITAL','CALC_AGE']]\n",
    "db_112.rename({'DIA_CODIGO': 'CIE', 'CALC_AGE': 'AGE', 'PAC_SEXO': 'SEX', 'LAB_RIESGO_VITAL': 'RISK'}, axis=1, inplace=True)\n",
    "\n",
    "db_112_texts = pd.read_csv(\"data/112/EM_112_ICD_selected.csv\")[['ARB_VARIABLES','VAR_Administración de medicación en el momento de la sintomatología','VAR_Alteraciones de la piel','VAR_Alteración de la conciencia','VAR_Alteración de la conducta','VAR_Antecedentes','VAR_Aparición manchas cutáneas','VAR_Apetito','VAR_Arritmia activa','VAR_Atención previa','VAR_Atragantamiento','VAR_Causalidad de la ingesta','VAR_Cianosis','VAR_Clínica vascular arterial (dolor, palidez y/o frialdad)','VAR_Clínica vascular venosa (calor, edema y enrojecimiento)','VAR_Congestión nasal','VAR_Consecuencias de la clínica','VAR_Consumo de sustancias tóxicas','VAR_Convulsiones','VAR_Crisis hipertensiva','VAR_Criterios código ICTUS','VAR_Criterios epidemiológicos','VAR_Cuadro Gastrointestinal (Náuseas, vómitos y/o diarrea)','VAR_Cuadro Vegetativo','VAR_Descompensación aguda de enfermedad mental','VAR_Desencadenantes de la clínica','VAR_Deshidratación','VAR_Deterioro nivel conciencia','VAR_Diarrea','VAR_Disnea','VAR_Disuria y/o Hematuria','VAR_Dolor','VAR_Edad','VAR_Embarazada','VAR_Enfermedad infecciosa epidemiológica','VAR_Estado de humor','VAR_Estreñimiento','VAR_Evolución clínica','VAR_Existencia de focalidad neurológica','VAR_Fallecimiento','VAR_Fiebre','VAR_Glucemia','VAR_Gravedad de la lesión/lesiones','VAR_Hemorragia','VAR_Inconsciente','VAR_Inconsciente recuperado','VAR_Ingesta de sustancia(Medicamento o Tóxicos)','VAR_Ingesta medicamentosa','VAR_Ingesta producto doméstico','VAR_Inicio de la clínica','VAR_Intento de suicidio activo','VAR_Lugar de hemorragia','VAR_Lugar del incidente','VAR_Mareo','VAR_Medicación habitual','VAR_Menstruación','VAR_Nivel de actividad','VAR_Nivel de relación y contacto','VAR_Náuseas','VAR_Número de heridos','VAR_Parto en curso','VAR_Picor','VAR_Quemadura','VAR_Respiración','VAR_Sangre o moco en heces','VAR_Signos de gravedad','VAR_Sin más información','VAR_Sustancia tóxica','VAR_Síndrome gripal','VAR_Síntomas de edema de glotis','VAR_Tiempo de evolución','VAR_Tipo alteración en la piel','VAR_Tipo de accidente','VAR_Tratamiento','VAR_Trauma previo','VAR_Vómitos','VAR_Vómitos alimenticios/biliosos','INC_OBSERVACIONES']]\n",
    "db_112_texts = db_112_texts.fillna(\"\")\n",
    "db_112_texts = db_112_texts.astype(str)\n",
    "\n",
    "db_112['TEXT_ES'] = db_112_texts.apply(''.join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case it has already been processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_112 = pd.read_excel(\"data/02_112_patients_db.xlsx\")\n",
    "db_112 = db_112.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_this(text):\n",
    "    return list(filter(None,re.split(\"\\s+\",re.sub(\"[,;.:\\*\\-–_<>/\\]\\[)(?!%$ºª°'“\\\"+=\\d\\s]+\", \" \",text.lower()))))\n",
    "\n",
    "def tokenize_and_filter(text):\n",
    "    if not pd.isna(text):\n",
    "        return [w for w in tokenize_this(text) if w not in get_stop_words()]\n",
    "    return []\n",
    "\n",
    "count_total= 0\n",
    "def tokenized_words_to_str(text):\n",
    "    global count_total\n",
    "    count_total = count_total + 1\n",
    "    if count_total % 10000 == 0:\n",
    "        print(count_total)\n",
    "    return \" \".join(map(str, tokenize_and_filter(text)))\n",
    "\n",
    "def get_all_words_one_list(list_of_lists):\n",
    "    list_of_words = []\n",
    "    for text_list in list_of_lists:\n",
    "        list_of_words.extend(text_list)\n",
    "    return list_of_words\n",
    "\n",
    "def get_stop_words():\n",
    "    stop_words = stopwords.words('english')\n",
    "    try:\n",
    "        f = open(\"stop_words/words_to_add.txt\", \"r\")\n",
    "        stop_words.extend(f.read().split(\"\\n\"))\n",
    "    finally: \n",
    "        return stop_words\n",
    "\n",
    "def days_to_year(days):\n",
    "    try:\n",
    "        return int(float(days)/365)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def es_to_en(texto):\n",
    "    return GoogleTranslator(source='es', target='en').translate(texto)\n",
    "\n",
    "def list_es_to_en(texts_es):\n",
    "    texts_en = []\n",
    "    for i in range(int(136160 / 20)):\n",
    "        in_es = \" \\n \".join(texts_es[i*20:(i+1)*20])\n",
    "        in_en = es_to_en(in_es).split(\"\\n\")\n",
    "        texts_en.extend(in_en)\n",
    "        print(f'{i}')\n",
    "    return texts_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize - Virtual Patients words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webs[\"T_HISTORY\"] = webs[\"HISTORY\"].apply(tokenize_and_filter)\n",
    "webs[\"T_EXAMINATION\"] = webs[\"EXAMINATION\"].apply(tokenize_and_filter)\n",
    "webs[\"T_GLOBAL\"] = webs[\"GLOBAL\"].apply(tokenize_and_filter)\n",
    "webs[\"TOKENIZED\"] = webs[\"T_HISTORY\"] + webs[\"T_EXAMINATION\"] + webs[\"T_GLOBAL\"]\n",
    "\n",
    "webs[\"RISKWORDS\"] = risk_words[\"RISKTEXTS\"].apply(tokenize_and_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize - 112 Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Cambiamos etiquetas de riesgo {2.0: 1, 1.0: 0}\n",
    "db_112['RISK'] = db_112['RISK'].apply(lambda value : int(value - 1))\n",
    "\n",
    "# 2) Actualizamos la edad a días\n",
    "db_112['AGE'] = db_112['CALC_AGE'].apply(days_to_year)\n",
    "\n",
    "# 3) Eliminamos la varibale Trauma previo__NO, puesto que la tokenizará en 3 distintas\n",
    "db_112['TEXT_ES'] = db_112['TEXT_ES'].apply(lambda text : text.replace('Trauma previo__NO', ''))\n",
    "\n",
    "# 4) Tokenizamos\n",
    "db_112['TEXT_ES'] = db_112['TEXT_ES'].apply(tokenized_words_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5) Traducimos al inglés\n",
    "db_112['TEXT'] = list_es_to_en(db_112['TEXT_ES'].tolist())\n",
    "\n",
    "# 6) Tokenizamos y filtramos stop words\n",
    "db_112['TEXT'] = db_112['TEXT'].apply(tokenized_words_to_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET STATISTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for Virtual Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_words = get_all_words_one_list(webs[\"TOKENIZED\"])\n",
    "print(f\"After tokenization and filtering, there are {len(all_words)} words in total.\")\n",
    "print(f\"For filtering, it has been used {len(get_stop_words())} words.\")\n",
    "print(f\"Total unique words: {len(set(all_words))}.\")\n",
    "#print(pd.DataFrame(all_words).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cases of 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In the 112-Database there are {len(db_112)} cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STORE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store - Virtual Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webs.drop(columns=['WEB','HISTORY','EXAMINATION','GLOBAL','T_HISTORY', 'T_EXAMINATION', 'T_GLOBAL'], inplace=True)\n",
    "webs.to_excel(\"./data/02_CIE_tokenized_info.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store - 112 Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_112.to_excel(\"./data/02_112_patients_db.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
